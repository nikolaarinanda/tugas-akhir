\newpage
\chapter{METODE PENELITIAN} \label{Bab III}

\section{Alur Penelitian} \label{III.Alur}
% Pada penelitian ini, alur dirancang untuk memastikan setiap tahapan pemrosesan dilakukan secara sistematis dan efisien. Alur penelitian ini mencerminkan langkah-langkah utama yang dilakukan pada penelitian ini, dapat dilihat pada Gambar \ref{fig:3.alur}. \par
Penelitian ini disusun melalui serangkaian langkah yang terstruktur untuk mencapai tujuan yang telah ditetapkan. Fokus utama penelitian adalah memberikan solusi yang dapat diterapkan terhadap permasalahan yang ada, yaitu dengan merancang dan mengimplementasikan sistem klasifikasi komentar \textit{cyberbullying} pada platform TikTok. Pendekatan yang digunakan mengombinasikan metode \textit{Text Convolutional Neural Network} (TextCNN), di mana TextCNN dimanfaatkan untuk mengekstraksi fitur-fitur penting dari teks komentar, sekaligus mempelajari pola sekuensial dalam teks guna meningkatkan akurasi klasifikasi. Set data pada penelitian ini akan melalui beberapa tahap pemrosesan, meliputi prapemrosesan teks, ekstraksi fitur, serta pelatihan model. Alur lengkap dari proses penelitian ini dapat dilihat pada Gambar \ref{fig:3.alur}.\par

\begin{figure}[H] % Kalau menggunakan H, posisi gambar akan tepat dibawah teks
    \centering
    \includegraphics[width=1\textwidth]{figure/alur-penelitian.png}
    \caption{Alur Penelitian}
    \label{fig:3.alur}
\end{figure}

\section{Penjabaran Langkah Penelitian} \label{III.Jabar Alur}
Untuk memperjelas setiap langkah-langkah yang telah didefinisikan pada Gambar \ref{fig:3.alur}, berikut ini akan dijelaskan secara rinci tahapan-tahapan yang dilakukan dalam penelitian ini.

\subsection{Identifikasi Masalah} \label{III.Identifikasi_masalah}
Tahap awal dalam penelitian ini dimulai dengan melakukan identifikasi terhadap permasalahan yang menjadi fokus utama. Penelitian ini bertujuan untuk mengklasifikasikan komentar \textit{cyberbullying} berdasarkan data yang diperoleh dari media sosial \textit{TikTok} dengan menggunakan metode \textit{TextCNN}. Permasalahan utama yang diangkat adalah kesulitan dalam mengenali komentar \textit{cyberbullying} pada kolom komentar \textit{TikTok}, mengingat gaya bahasa yang digunakan di media sosial umumnya bersifat informal, singkat, dan sering kali ambigu. 

Seiring meningkatnya penggunaan \textit{TikTok} sebagai sarana berekspresi, risiko munculnya tindakan \textit{cyberbullying} pun semakin besar, sehingga diperlukan sebuah model yang mampu mempelajari pola bahasa untuk melakukan klasifikasi komentar \textit{cyberbullying}. Penelitian ini bertujuan untuk mengembangkan model klasifikasi yang dapat memetakan konten teks ke dalam dua kategori, yaitu \textit{cyberbullying} dan \textit{non-cyberbullying}. 

Data yang digunakan pada penelitian ini diperoleh dari penelitian sebelumnya yang dilakukan oleh B.A. Prameswari \textit{et al.}, yang menyediakan kumpulan komentar \textit{TikTok} dengan dua label, yakni \textit{cyberbullying} dan \textit{non-cyberbullying} \cite{prameswari2023cyberbullying}. Pengembangan model dilakukan menggunakan metode \textit{TextCNN}, yang berperan dalam mengekstraksi fitur penting dari teks dan mempelajari hubungan sekuensial antar kata dalam kalimat untuk kemudian mengklasifikasikannya ke dalam dua label tersebut. Model ini akan dilatih menggunakan data yang telah melalui proses prapemrosesan, sehingga diharapkan dapat memberikan prediksi yang lebih akurat dalam mengklasifikasikan komentar \textit{cyberbullying} berdasarkan pola bahasa yang digunakan oleh pengguna \textit{TikTok}.
\par

\subsection{Tinjauan Pustaka} \label{III.Tinjauan_pustaka}
Pada tahap ini, dilakukan tinjauan terhadap berbagai penelitian terdahulu yang membahas klasifikasi komentar \textit{cyberbullying} berbasis media sosial, serta penelitian lain yang menggunakan metode serupa, khususnya dengan penerapan model \textit{TextCNN}. Tinjauan ini melibatkan beragam sumber referensi, termasuk \textit{paper}, jurnal, dan laporan penelitian yang relevan. Hasil dari studi literatur tersebut menjadi landasan penting bagi peneliti dalam memahami konsep, merancang metodologi, serta memperkuat kerangka teori yang mendasari penelitian ini.
\par

\subsection{Pengumpulan Dataset} \label{III.Pengumpulan_dataset}
    Pada penelitian ini, proses pengumpulan data tidak dilakukan secara langsung, melainkan menggunakan \textit{dataset} sekunder yang diperoleh dari penelitian sebelumnya oleh Prameswari \textit{et al.}~\cite{prameswari2023cyberbullying}. \textit{Dataset} tersebut terdiri atas 1.510 baris data dengan dua kolom utama, yaitu kolom \textit{sentiment} yang memuat dua label enumerasi: -1 untuk kategori \textit{cyberbullying} dan 1 untuk kategori \textit{non-cyberbullying}, serta kolom \textit{comment} yang berisi teks komentar. Contoh data pada Tabel \ref{table3:dataset} diambil dari berbagai baris data untuk representasi data yang lebih baik. Data ini selanjutnya akan diolah dan dimanfaatkan sebagai dasar dalam proses pelatihan model untuk melakukan klasifikasi emosi pada unggahan di media sosial.\par

    \begin{longtable}{|c|c|c|}
        \caption{Sample Isi Dataset} \label{table3:dataset} \\
            \hline
            \textbf{No Baris} & \textbf{Sentiment} & \textbf{Comment}\\
            \hline
        \endfirsthead
            \hline
            \textbf{No Baris} & \textbf{Sentiment} & \textbf{Comment}\\
            \hline
        \endhead 
            1 & -1 & Makannya segentong buset\\
            \hline
            2 & -1 & Mirip ursula di little mermaid\\
            \hline
            474 & 1 & Pede dulu, glow up belakangan\\
            \hline
            538 & 1 & Dihh keren banget\\
            \hline
            550 & 1& Pentingnya peradaban juga sis\\
            \hline
    \end{longtable}

\subsection{Prapemrosesan Data}
\label{III.Prapemrosesan_data}
Data dari \textit{dataset} yang diperoleh melalui sumber sekunder diproses terlebih dahulu melalui tahap prapemrosesan sebelum dilakukan analisis. Tahap prapemrosesan ini mencakup serangkaian teknik yang bertujuan untuk meningkatkan kualitas data sehingga lebih optimal digunakan dalam proses analisis dan pelatihan model. Beberapa langkah yang dilakukan meliputi \textit{case folding} untuk mengonversi seluruh teks menjadi huruf kecil, \textit{text cleaning} untuk menghapus karakter atau simbol yang tidak diperlukan, serta \textit{stopword removal} guna menghilangkan kata-kata yang tidak memberikan makna signifikan pada analisis. Setelah tahap prapemrosesan selesai, data kemudian dibagi menjadi dua bagian, yaitu 80\% untuk pelatihan (\textit{training}) dan 20\% untuk pengujian (\textit{testing}).\par

\subsection{\textit{Word Embedding}}
\label{III.Word_embedding}
Data yang telah melewati tahap prapemrosesan selanjutnya diproses menggunakan teknik \textit{word embedding} untuk mengubah teks menjadi representasi numerik yang dapat dipahami oleh model pembelajaran mesin. Pada penelitian ini, \textit{word embedding} diimplementasikan menggunakan pustaka PyTorch. Lapisan \textit{Embedding} ini bekerja dengan memetakan setiap kata dalam \textit{dataset} ke dalam representasi vektor berdimensi tetap berdasarkan indeks kata. 

Proses dimulai dengan membangun \textit{vocabulary}, yaitu daftar kata unik yang diperoleh dari \textit{dataset}. Setiap kata dalam \textit{vocabulary} diberikan indeks numerik, kemudian indeks tersebut dimasukkan ke dalam lapisan \textit{Embedding} untuk mendapatkan representasi vektor. Bobot awal pada lapisan \textit{Embedding} diinisialisasi secara acak dan akan diperbarui selama proses pelatihan model, sehingga representasi vektor yang dihasilkan dapat menyesuaikan dengan pola data dan meningkatkan kinerja model dalam klasifikasi.

\subsection{\textit{Modelling} (TextCNN)}
\label{III.Modelling}
Pada tahap ini, dilakukan proses klasifikasi terhadap data yang telah melewati tahap ekstraksi fitur agar model dapat mengenali pola-pola penting yang berkaitan dengan klasifikasi emosi. Proses klasifikasi dilakukan menggunakan arsitektur \textit{TextCNN}, yang dirancang khusus untuk menangani data teks. 

TextCNN bekerja melalui beberapa tahapan utama. Pertama, dilakukan proses \textit{convolution} menggunakan beberapa filter dengan ukuran kernel yang berbeda untuk mengekstraksi berbagai fitur penting dari data teks. Setiap filter bertujuan untuk menangkap pola kata dan frasa yang memiliki peran signifikan dalam penentuan kelas. Selanjutnya, hasil konvolusi melewati proses \textit{max pooling} yang berfungsi untuk mereduksi dimensi fitur tanpa kehilangan informasi esensial, sehingga membuat model lebih efisien dan fokus pada fitur paling relevan. 

Setelah tahap \textit{pooling}, hasilnya digabungkan dan diteruskan ke lapisan \textit{fully connected} untuk menghasilkan prediksi akhir. Dataset dibagi menjadi dua bagian, yaitu \textit{training data} yang digunakan untuk melatih model, serta \textit{testing data} yang digunakan untuk mengevaluasi kinerja model dalam mengklasifikasikan data baru.

\subsection{Evaluasi Model}
\label{III.Evaluasi_model}
Setelah model berhasil dibangun, tahap berikutnya adalah melakukan proses evaluasi untuk menilai kinerjanya dalam mengklasifikasikan emosi pada data berbasis media sosial. Evaluasi dilakukan dengan menghitung beberapa metrik utama, yaitu \textit{accuracy}, \textit{precision}, \textit{recall}, dan \textit{F1-score}. 

\textit{Accuracy} digunakan untuk mengukur sejauh mana model mampu mengklasifikasikan data secara benar secara keseluruhan. \textit{Precision} menilai tingkat ketepatan model dalam memprediksi data yang termasuk dalam kategori tertentu, sedangkan \textit{recall} mengukur sejauh mana model dapat menangkap seluruh data yang seharusnya termasuk dalam kategori tersebut. Sementara itu, \textit{F1-score} merupakan nilai harmonisasi antara \textit{precision} dan \textit{recall}, sehingga memberikan gambaran yang lebih seimbang mengenai performa model.

\section{Alat dan Bahan Tugas Akhir} \label{III.Alat dan Bahan}
Adapun alat dan bahan yang digunakan dalam penelitian ini adalah 
sebagai berikut:

\subsection{Alat} \label{III.Alat}
Berikut adalah alat yang digunakan dalam penelitian ini:
\begin{enumerate}
    \item Pada penelitian ini penulis menggunakan laptop dengan spesifikasi Sistem Operasi Windows 11 Home, AMD Ryzen 5 5600H, Memori 24GB DDR4, SSD 500GB.
    \item \textit{Visual Studio Code} v1.101.2, Miniconda v24.5.0, Python v3.12.4
\end{enumerate}

\subsection{Bahan} \label{III.Bahan}
Berikut adalah bahan yang digunakan dalam penelitian ini:
\begin{enumerate}
    \item \textit{Dataset} yang digunakan dalam penelitian ini merupakan \textit{dataset} sekunder yang diambil dari penelitian yang dilakukan oleh B.A. Prameswari \textit{el al}., dengan judul \textit{Building Prediction Model for Detecting Cyberbullying using TikTok Comments} \cite{prameswari2023cyberbullying}.

    \item Jurnal penelitian dari studi sebelumnya digunakan sebagai acuan untuk memberikan landasan teori, serta menyusun konsep dan gagasan yang mendukung pelaksanaan penelitian ini. 
\end{enumerate}

\section{Metode Pengembangan Model}
\label{III.Metode_pengembangan_model}
    Tahapan yang akan dilakukan dalam proses membangun model klasifikasi emosi menggunakan TextCNN dan hasil modifikasinya seperti SEDepthwise TextCNN dapat dilihat pada Gambar \ref{fig:3.metode_pengembangan_model}.

    \begin{figure}[H] % Kalau menggunakan H, posisi gambar akan tepat dibawah teks
        \centering
        \includegraphics[width=1\textwidth]{figure/metode-pengembangan.png}
        \caption{Metode Pengembangan}
        \label{fig:3.metode_pengembangan_model}
    \end{figure}

    \subsection{Pengumpulan Data}
    \label{III.Data_collecting}
        Dataset yang digunakan pada penelitian ini terdiri dari 1.510 baris komentar TikTok yang diklasifikasikan ke dalam dua kategori sentimen, yaitu \textit{cyberbullying} dan \textit{non-cyberbullying}. Dataset tersebut disajikan dalam format berkas \textit{CSV}. Setiap baris data berisi komentar \textit{TikTok} beserta label sentimen dalam bentuk nilai enumerasi, di mana nilai \textit{-1} menunjukkan \textit{cyberbullying} dan nilai \textit{1} menunjukkan \textit{non-cyberbullying}. Gambaran umum mengenai dataset dapat dilihat pada Tabel \ref{table3:sample_dataset_awal} yang menampilkan contoh data awal.

        \begin{longtable}{|c|c|}
            \caption{Sample Dataset Awal} \label{table3:sample_dataset_awal} \\
            \hline
                \textbf{\textit{Sentiment}} & \textbf{\textit{Comment}}\\
                \hline
                    -1 & Makannya segentong buset\\
                    \hline
                    -1 & Mirip ursula di little mermaid\\
                    \hline
                    ... & ...\\
                    \hline
                    1 & Pentingnya peradaban juga sis\\
                    \hline
                    1 & Pede dulu, glow up belakangan\\
            \hline
        \end{longtable}

    \subsection{Validasi Dataset}
    \label{III.Validasi_dataset}
        Validasi dataset merupakan proses pemeriksaan dan evaluasi untuk memastikan kualitas serta kelayakan data yang digunakan dalam penelitian. Tahap ini bertujuan untuk menjamin bahwa dataset bebas dari kesalahan yang berpotensi memengaruhi hasil analisis maupun kinerja model. Validasi dilakukan dengan cara memeriksa keberadaan data yang duplikat, hilang, atau tidak konsisten. Data yang duplikat dapat menyebabkan bias dalam pelatihan model, sehingga perlu diidentifikasi dan dihapus. Data yang hilang atau kosong juga perlu ditangani, baik dengan menghapus baris tersebut atau mengisi nilai yang sesuai berdasarkan konteks data. Selain itu, validasi juga mencakup pemeriksaan format data untuk memastikan kesesuaian dengan standar yang telah ditetapkan. Dengan melakukan validasi dataset secara menyeluruh, diharapkan data yang digunakan dalam penelitian ini memiliki kualitas yang baik dan dapat memberikan hasil analisis yang akurat serta dapat diandalkan.

    \subsection{Prapemrosesan Data}
    \label{III.Prapemrosesan_data}
        Prapemrosesan data merupakan serangkaian tahapan yang dirancang untuk mempersiapkan serta meningkatkan kualitas data teks agar siap digunakan pada proses analisis lebih lanjut. Tahapan ini umumnya mencakup konversi seluruh huruf menjadi huruf kecil (\textit{case folding}), penghapusan karakter atau simbol yang tidak diperlukan (\textit{text cleaning}), penambahan variasi data melalui proses augmentasi (\textit{data augmentation}), pemecahan teks menjadi satuan-satuan kata atau token (\textit{tokenization}), serta penghapusan kata-kata yang kurang relevan terhadap analisis (\textit{stopword removal}).

        \begin{enumerate} [left=2pt]
            \item \textit{Case Folding} \\
                \textit{Case folding} merupakan proses penyamaan format huruf pada teks dengan cara mengonversi seluruh karakter berhuruf besar (\textit{uppercase}) menjadi huruf kecil (\textit{lowercase}).

                \begin{longtable}{|c|p{4cm}|p{4cm}|}
                    \caption{Tahapan \textit{Case Folding}} \label{table3:tahapan_case_folding} \\
                    \hline
                        \textbf{Sentiment} & \textbf{Comment} & \textbf{Hasil} \\
                    \endfirsthead
                    \hline
                        \textbf{Sentiment} & \textbf{Comment} & \textbf{Hasil} \\
                    \endhead 
                    \hline
                    \endfoot
                    \hline
                    \endlastfoot
                    \hline
                        -1 & Cowo paling alay lebay se antero selebgram WKWKW NGAKAK & cowo paling alay lebay se antero selebgram wkwk ngakak \\
                        % \hline
                        % -1 & KU KIRA MUKA TERNYATA AMPELA & ku kira muka ternyata ampela\\
                    \hline
                \end{longtable}
            
            \item \textit{Text Cleaning}\\
                \textit{Text Cleaning} merupakan proses pembersihan teks dengan cara menghilangkan kata, karakter, atau elemen yang tidak diperlukan. Pada tahap ini, komponen yang dianggap tidak relevan atau dapat mengganggu analisis, seperti simbol, emoji, dan \textit{hashtag}, akan dihapus dari teks.

                \begin{longtable}{|c|p{4cm}|p{4cm}|}
                    \caption{Tahapan \textit{Text Cleaning}} \label{table3:text_cleaning} \\
                    \hline
                        \textbf{Sentiment} & \textbf{Comment} & \textbf{Hasil} \\
                    \endfirsthead
                    \hline
                        \textbf{Sentiment} & \textbf{Comment} & \textbf{Hasil} \\
                    \endhead 
                    \hline
                    \endfoot
                    \hline
                    \endlastfoot
                    \hline
                        -1 & udah sok tau salah pula \textbf{@}Ibnu Wardani ???? & udah sok tau salah pula ibnu wardani ???? \\
                    \hline
                \end{longtable}    

            \item \textit{Augmentation}\\
                \textit{Augmentation} adalah proses meningkatkan variasi data pelatihan dengan cara menghasilkan data baru yang berasal dari data yang sudah ada. Dalam penelitian ini, metode augmentasi yang digunakan adalah \textit{An Easier Data Augmentation} (AEDA), \textit{random swap}, dan \textit{random delete}.  AEDA adalah metode augmentasi yang dilakukan dengan menyisipkan tanda baca {".", ";", "?", ":", "!",","} secara acak kedalam teks asli \cite{karimi2021aeda}. Random swap dan random delete adalah metode augmentasi yang dilakukan dengan menukar huruf dalam satu kata secara acak dan menghapus huruf secara acak dalam teks asli \cite{wei2019eda}. Tujuan dari \textit{augmentation} adalah meningkatkan variasi data sehingga model dapat belajar lebih baik dan menghasilkan performa klasifikasi yang lebih akurat.

                \begin{longtable}{|c|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
                    \caption{Tahapan \textit{Augmentation}} \label{table3:augmentation} \\
                    \hline
                        \multirow{2}{*}{\textbf{Sentiment}} 
                        & \multirow{2}{*}{\textbf{Comment}} 
                        & \multirow{2}{*}{\textbf{Hasil}} 
                        & \multicolumn{2}{c|}{\textbf{Kata/Frasa yang Diubah}} \\ \cline{4-5}
                        &  &  & \textbf{Kata Asli} & \textbf{Kata Hasil} \\ 
                    \hline
                    \endfirsthead
                    
                    \hline
                        \multirow{2}{*}{\textbf{Sentiment}} 
                        & \multirow{2}{*}{\textbf{Comment}} 
                        & \multirow{2}{*}{\textbf{Hasil}} 
                        & \multicolumn{2}{c|}{\textbf{Kata/Frasa yang Diubah}} \\ \cline{4-5}
                        &  &  & \textbf{Kata Asli} & \textbf{Kata Hasil} \\ 
                    \hline
                    \endhead
                    
                    \hline
                    \endfoot
                    \hline
                    \endlastfoot
                        -1 & ngeliat mukanya aja udah gedeg & ngeliat mukanya aja udah kesal & ngeliat mukanya aja udah gedeg & ngeliat mukanya aja, udah gedeg! \\
                        \hline
                        1 & gue gapaham dr dulu fashion style dia kyk gmna wkwkwk & gue gapaham dr duul fashion style dia kyk gmna wkwkwk & dulu & duul \\
                        \hline
                        -1 & sebelum mangap di sikat dulu kale & sebelm mangap di sikat dulu kale & sebelum & sebelm \\        
                    \hline
                \end{longtable}

            \item \textit{Tokenization}\\
                \textit{Tokenization} merupakan tahap pemecahan teks menjadi unit-unit terkecil, seperti kata, frasa, atau kalimat. Tahapan ini berperan penting dalam membantu sistem komputer memahami struktur dan makna dari teks yang sedang dianalisis. Pada penelitan kali ini, proses \textit{tokenization} akan menggunakan \textit{tokenizer} IndoBERT yang telah dilatih sebelumnya untuk bahasa Indonesia. \textit{Tokenizer} ini mampu memecah teks menjadi token-token yang sesuai dengan konteks bahasa Indonesia, sehingga memudahkan model dalam memahami dan memproses data teks.

                \begin{longtable}{|c|p{4cm}|p{4cm}|}
                    \caption{Tahapan \textit{Tokenization}} \label{table3:tokenization} \\
                    \hline
                        \textbf{Sentiment} & \textbf{Comment} & \textbf{Hasil} \\
                    \hline
                    \endfirsthead
                
                    \hline
                        \textbf{Sentiment} & \textbf{Comment} & \textbf{Hasil} \\
                    \hline
                    \endhead
                
                    \hline
                    \endfoot
                
                    \hline
                    \endlastfoot
                    %     -1 & ngeliat mukanya aja udah kesal & 'ngeliat', 'mukanya', 'aja', 'udah', 'kesal' \\
                    % \hline
                        1 & aku penggemar mi burung dara enaknya nyambung terus & 'aku', 'penggemar', 'mi', 'burung', 'dara', 'enaknya', 'nyambung', 'terus' \\
                    \hline
                \end{longtable}

            \item \textit{Stopword Removal}\\
                \textit{Stopword removal} merupakan proses penghapusan kata-kata yang sering muncul dalam jumlah banyak namun dianggap tidak memiliki makna penting. Kata-kata yang umum tetapi kurang relevan, seperti konjungsi, kata kepunyaan, dan kata ganti orang, akan dihapus dari teks. Pada penelitian kali ini, proses \textit{stopword removal} dilakukan menggunakan daftar \textit{stopword} bahasa Indonesia yang telah disediakan oleh NLTK (\textit{Natural Language Toolkit}).

                \begin{longtable}{|c|p{3cm}|p{3cm}|p{2cm}|}
                    \caption{Tahapan \textit{Stopword Removal}} \label{table3:stopword_removal} \\
                    \hline
                        \textbf{Sentiment} & \textbf{Comment} & \textbf{Hasil} & \textbf{Kata yang Dihapus} \\
                    \hline
                    \endfirsthead
                
                    \hline
                        \textbf{Sentiment} & \textbf{Comment} & \textbf{Hasil} & \textbf{Kata yang Dihapus} \\
                    \hline
                    \endhead
                
                    \hline
                    \endfoot
                
                    \hline
                    \endlastfoot
                        1 & buatlah cita cita kamu setinggi bintang di langit tetapi jangan lupa untuk membuat anak tangga perencanaannya & buatlah cita cita setinggi bintang langit jangan lupa membuat anak tangga perencanaannya & 'kamu', 'di', 'tetapi', 'untuk' \\
                        % \hline
                        % -1 & minimal cuci muka lah goblok bikin sakit mata liatnya & minimal cuci muka goblok bikin sakit mata liatnya & 'lah' \\
                    \hline
                \end{longtable}
        \end{enumerate}

    \subsection{Pembagian Data}
    \label{III.Pembagian_data}
        \begin{figure}[H] % H agar posisi gambar tepat dibawah teks
            \centering
            \includegraphics[width=0.5\textwidth]{figure/pembagian-data.png}
            \caption{Pembagian Data}
            \label{fig:3.pembagian_data}
        \end{figure}

        Pada Gambar \ref{fig:3.pembagian_data} menunjukkan pembagian dataset dilakukan dengan rasio 80\% untuk data latih dan 20\% untuk data validasi. Data latih digunakan untuk melatih model, sementara data validasi berfungsi untuk menguji kinerja model yang telah dilatih. Pembagian data menggunakan \textit{stratified k-fold cross-validation} dapat diperoleh evaluasi yang lebih akurat mengenai seberapa baik model dapat melakukan generalisasi terhadap data yang belum pernah dilihat sebelumnya dan menghindari overfitting. 
        % Berikut ini ilustrasi dari \textit{stratified k-fold cross-validation} pada Gambar \ref{fig:3.stratified_kfold}.

        \begin{figure}[H] % Penggunaan H agar posisi gambar tepat dibawah teks 
            \centering
            \includegraphics[width=0.8\textwidth]{figure/k-fold.png}
            \caption{Arsitektur model TextCNN}
            \label{fig:3.stratified_kfold}
            {\footnotesize Sumber: internet}
        \end{figure}

        Ilustrasi pembagian dataset dengan teknik \textit{stratified k-fold cross validation} dapat dilihat pada Gambar \ref{fig:3.stratified_kfold}. Keseluruhan dataset terdiri dari data komentar TikTok yang dibagi menjadi 5 \textit{fold}, di mana setiap \textit{fold} berisi 20\% dari keseluruhan data. Lima \textit{fold} tersebut kemudian disusun menjadi 5 variasi \textit{split}, yang masing-masing terdiri atas 80\% data pelatihan dan 20\% data evaluasi. Setiap satu kali iterasi, proses pelatihan dilakukan sebanyak 5 kali menggunakan 5 \textit{fold} yang berbeda, dengan setiap \textit{fold} melatih model yang berbeda pula. Dengan demikian, pada proses pelatihan menggunakan \textit{k}-fold ini dihasilkan 5 model yang telah dilatih menggunakan 5 variasi pembagian dataset.

    \subsection{Arsitektur Model}
    \label{III.Arsitektur_model}
        Arsitektur model yang digunakan dalam penelitian ini adalah \textit{Text Convolutional Neural Network} (TextCNN) dan SEDepthwise TextCNN. Kedua model ini dirancang untuk menangani data teks dan melakukan klasifikasi berdasarkan fitur-fitur yang diekstraksi dari teks tersebut.

        \subsubsection{Arsitektur Model TextCNN}
        \label{III.Arsitektur_model_textcnn}
            TextCNN merupakan model klasifikasi teks berbasis algoritma \textit{Convolutional Neural Network} (CNN) yang dirancang khusus untuk memproses data teks. Diagram alur dari arsitektur TextCNN dapat dilihat pada Gambar \ref{fig:3.arsitektur_model_textcnn}.

            \begin{figure}[H] % H agar posisi gambar tepat dibawah teks
                \centering
                \includegraphics[width=0.5\textwidth]{figure/arsitektur-textcnn.png}
                \caption{Pembagian Data}
                \label{fig:3.arsitektur_model_textcnn}
            \end{figure}

            Gambar \ref{fig:3.arsitektur_model_textcnn} menunjukkan rancangan arsitektur model dasar TextCNN yang terdiri atas embedding layer, conv1d layer, ReLU, max pooling layer, concatenate layer, dropout layer, dan fully connected layer.

            \begin{enumerate}
                \item \textit{Embedding Layer}\\
                \textit{Embedding layer} berfungsi untuk mengonversi indeks kata menjadi vektor berdimensi kontinu. Pada tahap awal, parameter \textit{embedding} diinisialisasi secara acak. Selama proses pelatihan, parameter tersebut diperbarui melalui mekanisme \textit{backpropagation} secara end-to-end bersamaan dengan pelatihan model utama. Dengan demikian, representasi kata yang dihasilkan menjadi lebih kontekstual dan mampu menyesuaikan dengan karakteristik data yang digunakan. Pada penelitian ini, digunakan modul \textit{torch.nn.Embedding} dari \textit{PyTorch} untuk membangun representasi kata.

                \item \textit{Conv1D Convolutional Layer}\\
                Conv1D adalah operasi konvolusi yang banyak digunakan pada data sekuensial, seperti teks. Pada penelitian ini, Conv1D digunakan untuk mengekstraksi fitur penting dari data teks yang telah diubah menjadi representasi vektor melalui \textit{embedding layer}. Proses konvolusi dilakukan dengan menerapkan beberapa filter (kernel) berukuran berbeda pada data input. Setiap filter bertujuan untuk menangkap pola kata dan frasa yang memiliki peran signifikan dalam penentuan kelas. Dengan menggunakan berbagai ukuran kernel, model dapat mengenali beragam pola dalam teks yang mungkin relevan untuk klasifikasi.

                \item \textit{Activation Layer (ReLu)}\\
                \textit{Activation Layer} (ReLu) berfungsi untuk memperkenalkan non-linearitas ke dalam model setelah tahap konvolusi. Fungsi aktivasi ReLu (Rectified Linear Unit) digunakan untuk mengubah nilai negatif menjadi nol, sementara nilai positif tetap dipertahankan. Dengan demikian, ReLu membantu model untuk belajar representasi yang lebih kompleks dan mampu menangkap pola-pola non-linear dalam data teks. Penggunaan ReLu juga memiliki keuntungan dalam hal efisiensi komputasi, karena fungsi ini sederhana dan cepat untuk dihitung.

                \item \textit{Max Pooling Layer}\\
                \textit{Max Pooling Layer} berfungsi untuk mereduksi dimensi fitur yang dihasilkan dari tahap konvolusi. Proses ini dilakukan dengan cara mengambil nilai maksimum dari setiap jendela (window) yang bergerak melintasi fitur yang dihasilkan oleh filter konvolusi. Dengan demikian, max pooling membantu mengurangi jumlah parameter dalam model, sehingga meningkatkan efisiensi komputasi dan mengurangi risiko overfitting. Selain itu, max pooling juga menyoroti fitur-fitur paling dominan yang dianggap paling relevan untuk klasifikasi, sehingga model dapat fokus pada informasi penting yang diperlukan untuk membuat prediksi.

                \item \textit{Concatenate Layer}\\
                \textit{Concatenate Layer} berfungsi untuk menggabungkan hasil dari beberapa filter konvolusi yang telah melalui tahap \textit{max pooling}. Setiap filter dengan ukuran kernel yang berbeda akan mengekstraksi fitur yang berbeda pula dari data teks. Dengan menggabungkan hasil dari berbagai filter, model dapat memperoleh representasi fitur yang lebih kaya dan komprehensif. Proses \textit{concatenate} ini memungkinkan model untuk memanfaatkan informasi dari berbagai perspektif, sehingga meningkatkan kemampuan dalam mengenali pola-pola penting yang berkaitan dengan klasifikasi.

                \item \textit{Dropout Layer}\\
                \textit{Dropout Layer} berfungsi sebagai teknik regulasi untuk mencegah overfitting pada model. Pada tahap ini, sejumlah neuron dipilih secara acak dan "dijatuhkan" atau diabaikan selama proses pelatihan. Dengan demikian, model tidak terlalu bergantung pada neuron-neuron tertentu, sehingga dapat belajar representasi yang lebih umum dan \textit{robust}. Penggunaan \textit{dropout} membantu meningkatkan kemampuan generalisasi model terhadap data yang belum pernah dilihat sebelumnya, sehingga kinerja klasifikasi menjadi lebih baik.
                
                \item \textit{Fully Connected Layer}\\
                \textit{Fully Connected Layer} berfungsi untuk menggabungkan fitur-fitur yang telah diekstraksi dari tahap sebelumnya dan menghasilkan prediksi akhir. Pada tahap ini, semua neuron dari lapisan sebelumnya terhubung secara penuh ke setiap neuron di lapisan ini. Dengan demikian, model dapat memanfaatkan seluruh informasi yang telah dipelajari untuk membuat keputusan klasifikasi. Hasil dari \textit{fully connected layer} kemudian diteruskan ke fungsi aktivasi (seperti \textit{softmax} atau \textit{sigmoid}) untuk menghasilkan probabilitas prediksi terhadap kelas yang ditentukan.
            \end{enumerate}

        \subsubsection{Arsitektur Model SEDepthwise TextCNN}
        \label{III.Arsitektur_model_SEDepthwise_TextCNN}
            SEDepthwise TextCNN merupakan model klasifikasi teks yang didasarkan pada TextCNN asli menggunakan konvolusi terpisah dan squeeze-and-excitation (SE) blok untuk menangkap fitur yang lebih kaya dan relevan dari data teks. Diagram alur dari arsitektur SEDepthwise TextCNN dapat dilihat pada Gambar \ref{fig:3.arsitektur_model_SEDepthwise_TextCNN}.

            \begin{figure}[H] % H agar posisi gambar tepat dibawah teks
                \centering
                \includegraphics[width=0.5\textwidth]{figure/arsitektur-se-textcnn.png}
                \caption{Pembagian Data}
                \label{fig:3.arsitektur_model_SEDepthwise_TextCNN}
            \end{figure}

            Gambar \ref{fig:3.arsitektur_model_SEDepthwise_TextCNN} menunjukkan rancangan arsitektur model SEDepthwise TextCNN yang terdiri atas embedding layer, depthwise conv1d layer, pointwise conv1d layer, squeeze-and-excitation (SE) block, ReLU, max pooling layer, concatenate layer, dropout layer, dan fully connected layer.

            \begin{enumerate}
                \item \textit{Depthwise Conv1D Layer}\\
                \textit{Depthwise Conv1D Layer} adalah varian dari konvolusi satu dimensi (Conv1D) yang memisahkan proses konvolusi untuk setiap saluran input secara independen. Pada tahap ini, setiap filter diterapkan pada masing-masing saluran input tanpa menggabungkan informasi antar saluran. Dengan demikian, depthwise conv1d memungkinkan model untuk mengekstraksi fitur yang lebih spesifik dari setiap saluran, sehingga meningkatkan efisiensi komputasi dan mengurangi jumlah parameter yang perlu dipelajari. Pendekatan ini membantu model dalam menangkap pola-pola penting dalam data teks dengan cara yang lebih terfokus dan hemat sumber daya. \par

                \item \textit{Pointwise Conv1D Layer}\\
                \textit{Pointwise Conv1D Layer} adalah tahap konvolusi satu dimensi (Conv1D) yang menggunakan kernel berukuran 1. Pada tahap ini, setiap posisi dalam urutan data teks diproses secara individual, tanpa mempertimbangkan konteks dari posisi-posisi sekitarnya. Dengan demikian, pointwise conv1d memungkinkan model untuk menggabungkan informasi dari berbagai saluran yang telah diekstraksi pada tahap depthwise conv1d sebelumnya. Pendekatan ini membantu dalam mengintegrasikan fitur-fitur yang telah dipelajari dari setiap saluran, sehingga menghasilkan representasi yang lebih kaya dan komprehensif untuk klasifikasi teks. \par

                \item \textit{Squeeze-and-Excitation (SE) Block}\\
                \textit{Squeeze-and-Excitation (SE) Block} adalah mekanisme yang dirancang untuk meningkatkan representasi fitur dengan cara menyesuaikan bobot saluran fitur berdasarkan pentingnya masing-masing saluran. Pada tahap ini, fitur-fitur yang telah diekstraksi dari tahap konvolusi diproses melalui dua langkah utama: \textit{squeeze} dan \textit{excitation}. Pada langkah \textit{squeeze}, informasi spasial dari fitur-fitur tersebut diringkas menjadi vektor satu dimensi yang merepresentasikan setiap saluran. Selanjutnya, pada langkah \text{excitation}, vektor tersebut digunakan untuk menghasilkan bobot yang menyesuaikan kontribusi masing-masing saluran fitur. Dengan demikian, SE block memungkinkan model untuk fokus pada saluran-saluran yang lebih relevan, sehingga meningkatkan kemampuan dalam menangkap pola-pola penting yang berkaitan dengan klasifikasi teks. \par

            \end{enumerate}

\section{Ilustrai Perhitungan Metode}
\label{III.Ilustrasi_perhitungan_metode}
    Pada tahap ini, dilakukan ilustrasi perhitungan metode \textit{TextCNN} yang digunakan dalam penelitian ini. Ilustrasi ini mencakup langkah-langkah utama dalam proses klasifikasi teks, mulai dari representasi kata hingga prediksi akhir.

    \subsection{\textit{Input Layer (\textit{Token IDs})}}
        Setelah melalui tahapan pemrosesan data, teks input diubah menjadi representasi numerik berupa token ID melalui \textit{tokenizer} IndoBERT. Ini dilakukan agar teks dapat diproses oleh model pembelajaran mesin. Berikut ini adalah tabel yang menunjukkan contoh teks input beserta token ID yang dihasilkan.

        \newpage
        \begin{longtable}{|c|c|}
        \caption{Sample Dataset Awal} \label{table3:sample_token_ids} \\
        \hline
            \textbf{\textit{Token ID}} 
            & \textbf{\textit{Comment}}\\
        \hline
            245 & Makannya\\
            \hline
            ... & ...\\
            \hline
            678 & Segentong\\
            \hline
            ... & ...\\
            \hline
            934 & Buset\\
        \hline
        \end{longtable}

        Dari token ID yang dihasilkan oleh proses tokenisasi, kemudian teks input berupa kalimat "Makannya segentong buset" dipetakan menjadi token ID sebagai berikut:

        \begin{equation*}
            \text{"Makannya segentong buset"} \;\;\mapsto\;\; [245, 678, 934]
        \end{equation*}

    \subsection{\textit{Embedding Layer}}
        Proses \textit{word embedding} adalah proses awal dimana token ID diubah menjadi representasi vektor berdimensi tetap. Misalnya, token ID \textit{245}, \textit{678}, dan \textit{934} dipetakan ke dalam vektor embedding berdimensi 4 sebagai berikut:

        \begin{equation*}
            \begin{split}
                \mathbf{x}_1 &= W_{245} = [0.1,\, 0.3,\, 0.5,\, 0.7] \\
                \mathbf{x}_2 &= W_{678} = [0.2,\, 0.4,\, 0.6,\, 0.8] \\
                \mathbf{x}_3 &= W_{934} = [0.3,\, 0.5,\, 0.7,\, 0.9]
            \end{split}
            % W_i \in \mathbb{R}^{3 \times 4}
        \end{equation*}
        \vspace{2em}

        Hasil embedding seluruh token ID akan membentuk matriks:
        \vspace{1em}

        \begin{equation*}
            \begin{split}
                E \in \mathbb{R}^{3 \times 4},
                \quad
                E = 
                \begin{bmatrix}
                    \mathbf{x}_1 \\
                    \mathbf{x}_2 \\
                    \mathbf{x}_3
                \end{bmatrix} =
                \begin{bmatrix}
                    0.1 & 0.3 & 0.5 & 0.7 \\
                    0.2 & 0.4 & 0.6 & 0.8 \\
                    0.3 & 0.5 & 0.7 & 0.9 \\
                \end{bmatrix}
            \end{split}
            \quad
        \end{equation*}

    \subsection{\textit{Permute Operation}}
        Agar sesuai dengan format Conv1D PyTorch, dilakukan transpose matriks embedding untuk merubah bentuk matrix dari (\textit{vocabulary size, embedding dimmention}) menjadi (\textit{embedding dimmention, vocabulary size}).
        \vspace{1em}
        
        \begin{equation*}
            E' \in \mathbb{R}^{4 \times 3},
            \quad
            E' =
            \begin{bmatrix}
                0.1 & 0.2 & 0.3 \\
                0.3 & 0.4 & 0.5 \\
                0.5 & 0.6 & 0.7 \\
                0.7 & 0.8 & 0.9 \\
            \end{bmatrix}
        \end{equation*}

    \subsection{\textit{Convolutional Layer}}
        \subsubsection{\textit{Conv1D}}
        Pada layer konvolusi, dilakukan operasi konvolusi pada matriks embedding yang telah ditranspose. Perhitungan konvolusi pada posisi $i$ dilakukan dengan rumus:

        \begin{equation*}
            Z[i] = \sum_{j=0}^{k-1} X[i+j] \times W[j] + b
        \end{equation*}
        \vspace{1em}

        Misalkan pada tahap konvolusi dengan kernel size 2  setiap filter memiliki bobot sebagai berikut:
        \vspace{1em}

        \begin{equation*}
            W =
            \begin{bmatrix}
                0.2 & 0.1 & -0.1 & 0.5 \\
                0.3 & -0.2 & 0.4 & 0.1 \\
            \end{bmatrix}
            % ,
            % \quad
            % b = [0.1,\, 0.2]
        \end{equation*}
        \vspace{2em}

        \noindent{Dengan asumsi:}
            \begin{flushleft}
                kernel size = 2 \par
                stride = 1 \par
                bias = 0.2 \par
            \end{flushleft}
        \vspace{1em}

        % \begin{enumerate}[label=\alph*)]
        \begin{enumerate}
            \item Window 1: Makannya + segentong \\
                \begin{align*}
                    \text{output} &= 
                    (0.1)(0.2) + (0.3)(0.1) + (0.5)(-0.1) + (0.7)(0.5) + \\
                    &\quad (0.2)(0.3) + (0.4)(-0.2) + (0.6)(0.4) + (0.8)(0.1) \\
                    &= 0.65 + 0.2 \;(\text{bias}) \\
                    &= 0.85
                \end{align*}
            \item Window 2: segentong + buset \\
                \begin{align*}
                    \text{output} &= 
                    (0.2)(0.2) + (0.4)(0.1) + (0.6)(-0.1) + (0.8)(0.5) + \\
                    &\quad (0.3)(0.3) + (0.5)(-0.2) + (0.7)(0.4) + (0.9)(0.1) \\
                    &= 0.68 + 0.2 \;(\text{bias}) \\
                    &= 0.88
                \end{align*}
        \end{enumerate}
        \vspace{1em}

        Misalkan pada tahap konvolusi dengan kernel size 3  setiap filter memiliki bobot sebagai berikut:
        \vspace{1em}

        \begin{equation*}
            W =
            \begin{bmatrix}
                0.2 & 0.1 & -0.1 & 0.5 \\
                0.3 & -0.2 & 0.4 & 0.1 \\
                0.4 & 0.3 & 0.2 & 0.2 \\
            \end{bmatrix}
            % ,
            % \quad
            % b = [0.1,\, 0.2]
        \end{equation*}
        \vspace{2em}

        \noindent{Dengan asumsi:}
            \begin{flushleft}
                kernel size = 3 \par
                stride = 1 \par
                bias = 0.2 \par
            \end{flushleft}
        \vspace{1em}

        % \begin{enumerate}[label=\alph*)]
        \begin{enumerate}
            \item Window 1: Makannya + segentong + buset \\
                \begin{align*}
                    \text{output} &= 
                    (0.1)(0.2) + (0.3)(0.1) + (0.5)(-0.1) + (0.7)(0.5) + \\
                    &\quad (0.2)(0.3) + (0.4)(-0.2) + (0.6)(0.4) + (0.8)(0.1) \\
                    &\quad (0.3)(0.4) + (0.5)(0.3) + (0.7)(0.2) + (0.9)(0.2) \\
                    &= 0.68 + 0.2 \;(\text{bias}) \\
                    &= 0.88
                \end{align*}
        \end{enumerate}

    \subsection{\textit{Activation Layer (ReLU)}}
        Untuk mengeliminasi nilai negatif dan mempertahankan nilai positif, hasil konvolusi $Z[i]$ dilewatkan ke fungsi aktivasi ReLU:
        \vspace{1em}

        \begin{equation*}
            c_i = f(Z[i]) = \max(0, Z[i])
        \end{equation*}

        \vspace{2em}

        Contoh hasil \textit{feature map} setelah ReLU:

        \begin{equation*}
            \begin{split}
                % \text{Kernel 2} \;\rightarrow\; [0.2,\, 0.9,\, 0.5] \\
                % \text{Kernel 4} \;\rightarrow\; [0.4,\, 0.7,\, 0.2]
                C_1 = [0.85,\, 0.88] \\
                C_2 = [0.88]
            \end{split}
        \end{equation*}

    \subsection{\textit{Max Pooling Layer}}
        Ambil nilai maksimum dari setiap \textit{feature map} untuk merangkum informasi paling penting:
        \vspace{1em}

        \begin{equation*}
            \begin{split}
                % \text{Kernel 2} &\;\rightarrow\; \max([0.2,\, 0.9,\, 0.5]) = 0.9 \\
                % \text{Kernel 4} &\;\rightarrow\; \max([0.4,\, 0.7,\, 0.2]) = 0.7
                \text{MaxPool}(C_1) = \max(0.85, 0.88) = 0.88 \\
                \text{MaxPool}(C_2) = \max(0.88) = 0.88
            \end{split}
        \end{equation*}
        \vspace{2em}

        Sehingga output pooling adalah:
        \vspace{1em}

        \begin{equation*}
            \begin{bmatrix}
                0.88 \\
                0.88
            \end{bmatrix}
        \end{equation*}

    \subsection{\textit{Concatenation Layer}}
        Gabungkan hasil pooling dari semua filter menjadi satu vektor fitur gabungan:

        \vspace{1em}

        \[
            \text{Fitur Gabungan} = 
            \begin{bmatrix}
                0.88 \\
                0.88
            \end{bmatrix} =
            [0.88, 0.88]
        \]

        \vspace{2em}

        Jika ada lebih banyak filter, tambahkan hasil pooling mereka ke vektor ini.

    \subsection{\textit{Dropout Layer}}
        Dengan dropout rate 0.1 (10\% neuron dimatikan acak saat training).

        \[
            \text{Fitur Gabungan Setelah Dropout} = [0.88, 0.88]
        \]

    \subsection{\textit{Fully Connected Layer}}
        Fully connected layer mengubah vektor fitur gabungan menjadi skor untuk setiap kelas. Fungsi aktivasi \textit{softmax} kemudian digunakan untuk mengubah skor ini menjadi probabilitas prediksi untuk setiap kelas.
        \vspace{1em}

        \begin{equation*}
            \text{softmax}(z_i) = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}}
        \end{equation*}
        \vspace{1em}

        Misalnya hasil perhitungan adalah:
        \vspace{1em}
        \begin{equation*}
            \text{Output} = 
            \begin{bmatrix}
            1.086 \\
            0.888
            \end{bmatrix}
        \end{equation*}
        \vspace{1em}

        Maka probabilitas prediksi untuk setiap kelas adalah:
        \vspace{1em}

        \begin{equation*}
            \begin{split}
                P(\text{Kelas 1}) &= \frac{e^{1.086}}{e^{1.086} + e^{0.888}} \approx 0.57 \\
                P(\text{Kelas 2}) &= \frac{e^{0.888}}{e^{1.086} + e^{0.888}} \approx 0.43
            \end{split}
        \end{equation*}

\section{Rancangan Pengujian}
\label{III.Pengujian}
    Rancangan pengujian dilakukan secara sistematis agar hasil evaluasi bersifat andal, terukur, dan dapat direplikasi.

    % \subsection{Konsep Studi Ablasi}
        % Studi ablasi dilakukan untuk menilai kontribusi masing-masing komponen dalam arsitektur model TextCNN. Pada tahap ini, setiap komponen utama, seperti \textit{embedding layer}, \textit{convolutional layer}, \textit{pooling layer}, dan \textit{fully connected layer}, akan dihapus satu per satu. Setelah itu, model akan dilatih ulang dan dievaluasi menggunakan metrik yang sama seperti pada model lengkap. Dengan membandingkan kinerja model tanpa komponen tertentu dengan model lengkap, dapat diketahui seberapa besar pengaruh masing-masing komponen terhadap performa keseluruhan. Hasil dari studi ablasi ini memberikan wawasan penting mengenai bagian-bagian mana yang paling krusial dalam arsitektur TextCNN untuk tugas klasifikasi teks.

    \subsection{Skema Pengujian}
        Pada tahap ini, dilakukan proses pengujian untuk menilai kinerja model yang telah dibangun. Pengujian dilakukan dengan menggunakan 5 fold data yang telah dipisahkan sebelumnya sebagai data latih dan data validasi. Hasil prediksi dari model akan dibandingkan dengan label asli untuk menghitung metrik evaluasi seperti \textit{accuracy} yang dihitung berdasarkan rumus \ref{eq:2.accuracy}, \textit{precision} yang dihitung berdasarkan rumus \ref{eq:2.precision}, \textit{recall} yang dihitung berdasarkan rumus \ref{eq:2.recall}, dan \textit{F1-score} yang dihitung berdasarkan rumus \ref{eq:2.f1score}. Metrik-metrik ini memberikan gambaran mengenai seberapa baik model dalam mengklasifikasikan data baru dan membantu mengidentifikasi area yang perlu ditingkatkan.
        Disini diasumsikan \textit{confusion matrix} seperti pada Gambar \ref{fig:3.hasil_prediksi} dan Tabel \ref{table:hasil_prediksi}.

        \begin{figure}[H] % H digunakan agar posisi gambar tepat berada dibawah teks 
            \centering
            \includegraphics[width=0.6\textwidth]{figure/hasil-prediksi.png}
            \caption{Inisialisasi \textit{Confusion Matrix}}
            \label{fig:3.hasil_prediksi}
            % {\footnotesize Sumber: dokumen pribadi}
        \end{figure}

        \begin{longtable}{|c|c|c|c|}
            \caption{Inisialisasi \textit{Confusion Matrix}} \label{table:hasil_prediksi} \\
            \hline
                \multirow{2}{*}{\textbf{Aktual}} & \multicolumn{2}{c|}{\textbf{Prediksi}} \\ \cline{2-3}
                & \textbf{Positif} & \textbf{Negatif} & \textbf{Total Prediksi} \\ \hline
                \endfirsthead
            \hline
                \multirow{2}{*}{\textbf{Aktual}} & \multicolumn{2}{c|}{\textbf{Prediksi}} \\ \cline{2-3}
                & \textbf{Positif} & \textbf{Negatif} & \textbf{Total Prediksi} \\ \hline
                \endhead
                \textbf{Positif} & 94 & 48 & 142 \\ \hline
                \textbf{Negatif} & 27 & 102 & 129 \\  \hline
                \textbf{Total Aktual} & 121 & 150 & 271 \\
            \hline
        \end{longtable}

        Berdasarkan \textit{confusion matrix} pada Gambar \ref{fig:3.hasil_prediksi} dan Tabel \ref{table:hasil_prediksi} dapat ditarik beberapa kesimpulan. Dari total 142 data dengan label asli \textit{Cyberbullying}, sebanyak 94 data berhasil diklasifikasikan dengan benar (True Positive). Sementara itu, terdapat 48 data yang salah diklasifikasikan sebagai \textit{Non-Cyberbullying} (False Negative). selanjutnya, dari total 129 data dengan label asli \textit{Non-Cyberbullying}, sebanyak 102 data berhasil diklasifikasikan dengan benar (True Negative), sedangkan 27 data salah diklasifikasikan sebagai \textit{Cyberbullying} (False Positive).  Dengan informasi ini, dapat dihitung metrik evaluasi seperti \textit{accuracy}, \textit{precision}, \textit{recall}, dan \textit{F1-score} untuk menilai kinerja model dalam mengklasifikasikan data. Berikut adalah perhitungan metrik evaluasi berdasarkan nilai-nilai pada \textit{confusion matrix} di atas: \\
        TP = 94 \\
        FN = 48 \\
        FP = 27 \\
        TN = 102

        \begin{equation*}
            \textit{Accuracy} = \frac{TP + TN}{TP + FP + FN + TN} = \frac{94 + 102}{94 + 27 + 48 + 102} = \frac{196}{271} = 0.7236
        \end{equation*}
        \vspace{1cm}
            
        \begin{equation*}
            \textit{Precision} = \frac{TP}{TP + FP} = \frac{94}{94 + 27} = \frac{94}{121} = 0.7777
        \end{equation*}
        \vspace{1cm}

        \begin{equation*}
            \textit{Recall} = \frac{TP}{TP + FN} = \frac{94}{94 + 48} = \frac{94}{142} = 0.6611
        \end{equation*}
        \vspace{1cm}

        \begin{equation*}
            \textit{F1-Score} = 2 \times \frac{\textit{Precision} \times \textit{Recall}}{\textit{Precision} + \textit{Recall}} = 2 \times \frac{0.7777 \times 0.6611}{0.7777 + 0.6611} = 0.7156
        \end{equation*}
        \vspace{1cm}

        Berdasarkan nilai-nilai tersebut, diperoleh nilai accuracy sebesar 0,7236, yang mengindikasikan bahwa 72,36\% dari semua prediksi adalah benar. Nilai precision sebesar 0,7777, yang mengindikasikan bahwa 77,77\% dari semua prediksi Cyberbullying adalah benar. Nilai recall sebesar 0,6611 menunjukkan bahwa model berhasil mengidentifikasi 66,11\% dari seluruh data kelas Cyberbullying secara tepat. Nilai F1-score, yaitu rata-rata harmonis dari precision dan recall, berada pada angka 0,7156.

        \begin{longtable}{|c|c|c|c|c|}
            % \caption{Tahapan \textit{Stopword Removal}} \label{table3:stopword_removal} \\
            \hline
            \textbf{Kelas} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
            \hline
            \endfirsthead
                1 & 0.7236 & 0.7777 & 0.6611 & 0.7156 \\
            \hline
        \end{longtable}

% \subsection{Map Pengujian}
    % Dalam penelitian ini, hasil perhitungan dari program akan melalui serangkaian pengujian untuk mengevaluasi tingkat keakuratan model yang digunakan. Data dummy tersebut dapat dilihat pada Tabel \ref{table:3.dummy}. \par
    % \begin{longtable}{|c|c|c|c|c|c|c|c|c|}
    % 	\caption{Data \textit{dummy} Pengujian}
    % 	\label{table:3.dummy}\\
    % 	\hline
    % 	\multirow{2}{*}{\textbf{Subjek}} & \multicolumn{7}{|c|}{\textbf{Hasil Prediksi (BPM)}} & \multirow{2}{*}{\textbf{GT}} \\ \cline{2-8}
    %     & \textbf{F} & \textbf{NA} & \textbf{NO} & \textbf{RC} & \textbf{LC} & \textbf{M} & \textbf{C} & \\ 
    %         \hline
    % 	   \endfirsthead
    %        \hline
    %        \multirow{2}{*}{\textbf{Subjek}} & \multicolumn{7}{|c|}{\textbf{Hasil Prediksi (BPM)}} & \multirow{2}{*}{\textbf{GT}} \\ \cline{2-8}
    %     & \textbf{F} & \textbf{NA} & \textbf{NO} & \textbf{RC} & \textbf{LC} & \textbf{M} & \textbf{C} & \\ 
    %     \hline
    % 	\endhead
    % 	\hline
    % 	\endfoot
    % 	\hline
    % 	\endlastfoot
    % 	1 & 68 & 69 & 68 & 70 & 68 & 71 & 69 & 68 \\ 
    % 	\hline
    % 	2 & 69 & 69 & 68 & 70 & 68 & 71 & 69 & 69 \\
    % 	\hline
    % 	3 & 70 & 70 & 69 & 71 & 68 & 73 & 69 & 70\\
    % 	\hline
    % 	4 & 71 & 70 & 70 & 72 & 69 & 73 & 70 & 71 \\
    % 	\hline
    % 	5 & 72 & 72 & 70 & 72 & 70 & 74 & 70 & 72 \\
    % 	\hline
    %         6 & 73 & 72 & 71 & 74 & 71 & 76 & 71 & 73 \\ 
    % 	\hline
    % 	7 & 74 & 73 & 72 & 74 & 72 & 77 & 71 & 74 \\
    % 	\hline
    % 	8 & 75 & 74 & 72 & 74 & 73 & 77 & 73 & 75\\
    % 	\hline
    % 	9 & 76 & 75 & 73 & 75 & 74 & 78 & 75 & 76 \\
    % 	\hline
    % 	10 & 77 & 76 & 74 & 78 & 75 & 78 & 76 & 77
    % \end{longtable}